
2023-10-23 Mon: I implemented a new design for the button screen. Updated the hardcoded Hard Coded ONE Value to 2111.01 ONE on the dashboard and buttons screen. Added press speak functionality, Add functionality for the 'Press Speak' feature. Incorporate a soft beep every second to indicate waiting for ChatGPT response. Completed the remaining button functionalities, excluding the 'Fast Forward' action. Enable presentation mode for the application. Temporarily commented out the Dashboard code. If it is required in the future, we can easily reintegrate it.

---

2023-10-20 Fri: I implemented a fresh design for the button screen, featuring buttons for pause, reset, speak, cut, hide, and repeat. I also focused on refining their respective action functionalities. However, the reset action is encountering certain issues that require further attention. I addressed the font-related problem occurring in portrait mode and applied the necessary fixes. Subsequently, I have deployed the most recent changes to TestFlight for evaluation. 

2023-10-19 Thu: Implemented buttons on a new screen for pause, reset, speak, cut, hide, and repeat, and currently working on their action functionalities.

2023-10-18 Wed: Upgraded speech detection, integrated ChatGPT4, added Apple's text-to-speech, and implemented Figma's design specifications.

2023-10-17 Tue: Currently, I am developing an end-to-end demo for iOS. As part of this project, I have successfully integrated a text-to-speech functionality leveraging Apple's native capabilities. Presently, I am focused on refining the speech-detection component of the project.

2023-10-16 Mon: Successfully utilized SwiftUI to create a dynamic dashboard design, ensuring seamless adaptation to both portrait and landscape orientations. The dashboard prominently displays a central text element and incorporates essential static information in all four corners.

---

2023-10-14 Sat: Per [x.country/sam](x.country/sam), the first task is to build the first and only screen. For now, just display a number "256 ms" to indicate the end-to-end latency. Then: The overall system at center and 3 component latencies, measured as 5-second running averages, are for optimizing network and API performance of speech recognition, ChatGPT4 response, speech synthesis.


Bio: Experienced Lead iOS Engineer with a demonstrated history of working in the computer software industry. Skilled in, Swift, Objective-C, CoreData,Github, SQL, C++, OpenCV, Continues integration and Agile Methodologies. Strong information technology professional with a Master of Computer Applications (M.C.A.) focused in Computer Science from Loyola Academy.

https://www.linkedin.com/in/nageshkumarmishra
